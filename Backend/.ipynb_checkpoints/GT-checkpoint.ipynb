{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615cad17-4d15-4229-b2ec-28d001c0726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.1/55.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 0.4/1.5 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.8/1.5 MB 10.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.5 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 133.4/133.4 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB ? eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 53.6/53.6 kB ? eta 0:00:00\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.0/65.0 kB ? eta 0:00:00\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17461 sha256=3a816b3dba1776df562d4b8d4146900a6cb5e36aeb1c2eb6c2816c6ed4373ebc\n",
      "  Stored in directory: c:\\users\\enigma\\appdata\\local\\pip\\cache\\wheels\\60\\b3\\27\\d8aff3e2d5c2d0d97a117cdf0d5f13cd121e2c2b5fb49b55a0\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.14.0 requires flatbuffers>=23.5.26, but you have flatbuffers 1.12 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.9.0 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires ml-dtypes==0.2.0, but you have ml-dtypes 0.3.1 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires numpy>=1.23.5, but you have numpy 1.23.1 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires tensorboard<2.15,>=2.14, but you have tensorboard 2.9.0 which is incompatible.\n",
      "tensorflow-intel 2.14.0 requires tensorflow-estimator<2.15,>=2.14.0, but you have tensorflow-estimator 2.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c041cb38-48d5-49e9-a3da-9badf593083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from io import BytesIO\n",
    "\n",
    "def create_pdf_from_text(text, output_pdf_path):\n",
    "    buffer = BytesIO()\n",
    "    doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest='en').text\n",
    "\n",
    "    translated_text = Paragraph(translated_text, styles[\"Normal\"])\n",
    "    story.append(translated_text)\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    with open(output_pdf_path, 'wb') as f:\n",
    "        f.write(buffer.getvalue())\n",
    "\n",
    "# Your original text to be translated\n",
    "original_text = \"\"\"Art 8 • Vie privée et familiale • Refus des juridictions internes d’examiner \n",
    "l’action du requérant, affirmant être le père biologique d’un enfant, visant à \n",
    "contester la paternité légalement établie en vue de faire établir la sienne, en \n",
    "l’application des règles de computation du délai de forclusion de cinq ans \n",
    "combinées avec l’obligation d’attraire en la cause l’enfant • Requérant n’ayant \n",
    "pas agi dès la connaissance de sa paternité alors qu’il disposait d’un délai \n",
    "suffisant de plus de trois ans pour engager une action • Requérant ayant tardé à \n",
    "mettre dans la cause l’enfant sans justifier avoir pu ignorer l’existence de cette \n",
    "règle constante en droit interne • Conclusions des juridictions internes ni \n",
    "arbitraires ni déraisonnables • Refus fondé sur un lien de filiation déjà établi pour \n",
    "l’enfant et au regard de l’intérêt supérieur de ce dernier • Décisions judiciaires \n",
    "n’ayant pas abouti en pratique à priver le requérant de tout lien avec l’enfant • \n",
    "Juste équilibre ménagé entre les différents intérêts en présence\"\"\"\n",
    "\n",
    "# Output PDF path\n",
    "output_pdf_path = \"GTtranslated_output.pdf\"\n",
    "\n",
    "# Translate and create the PDF\n",
    "create_pdf_from_text(original_text, output_pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35bd138b-c9f4-444b-894b-62a71d63698d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m output_pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdfGTtranslated_output.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m target_language \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the target language code, e.g., \"fr\" for French\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[43mtranslate_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_pdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m, in \u001b[0;36mtranslate_pdf\u001b[1;34m(input_pdf_path, output_pdf_path, target_language)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_pdf\u001b[39m(input_pdf_path, output_pdf_path, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     36\u001b[0m     extracted_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(input_pdf_path)\n\u001b[1;32m---> 37\u001b[0m     translated_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     create_pdf_from_text(translated_text, output_pdf_path)\n",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m, in \u001b[0;36mtranslate_text\u001b[1;34m(text, target_language)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     17\u001b[0m     translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m---> 18\u001b[0m     translated_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m translated_text\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\googletrans\\client.py:219\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    218\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(resp)\n\u001b[1;32m--> 219\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# not sure\u001b[39;00m\n\u001b[0;32m    221\u001b[0m should_spacing \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not NoneType"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from googletrans import Translator\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def translate_text(text, target_language='en'):\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest=target_language).text\n",
    "    return translated_text\n",
    "\n",
    "def create_pdf_from_text(text, output_pdf_path):\n",
    "    buffer = BytesIO()\n",
    "    doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "\n",
    "    translated_text = Paragraph(text, styles[\"Normal\"])\n",
    "    story.append(translated_text)\n",
    "\n",
    "    doc.build(story)\n",
    "\n",
    "    with open(output_pdf_path, 'wb') as f:\n",
    "        f.write(buffer.getvalue())\n",
    "\n",
    "def translate_pdf(input_pdf_path, output_pdf_path, target_language='en'):\n",
    "    extracted_text = extract_text_from_pdf(input_pdf_path)\n",
    "    translated_text = translate_text(extracted_text, target_language)\n",
    "    create_pdf_from_text(translated_text, output_pdf_path)\n",
    "\n",
    "# Example usage:\n",
    "input_pdf_path = \"./uploads/AFFAIRE C.P. ET M.N. c. FRANCE.pdf\"  # Replace with the path to your input PDF\n",
    "output_pdf_path = \"pdfGTtranslated_output.pdf\"\n",
    "target_language = \"en\"  # Replace with the target language code, e.g., \"fr\" for French\n",
    "\n",
    "translate_pdf(input_pdf_path, output_pdf_path, target_language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c692b7-f403-4fd2-8420-e24877f471f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

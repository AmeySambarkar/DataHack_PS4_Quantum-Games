{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dcd5b94-5117-4525-a328-38bd0f3a1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8338f63-8ef0-471d-93bd-ff61b60f3b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "pdf_path=\"./uploads/AFFAIRE A.A.K. c. TÜRKiYE.pdf\"\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = ''\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "df = extract_text_from_pdf(pdf_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd4469a-ea37-4271-8f19-98bd0f903f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = \"t5-small\"  # Adjust to the model you choose\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89656a6-e495-4297-9c24-1e0a287d29f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: frontend in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: starlette>=0.12.0 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from frontend) (0.31.1)\n",
      "Requirement already satisfied: uvicorn>=0.7.1 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from frontend) (0.23.2)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from frontend) (2.1.2)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from frontend) (23.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from starlette>=0.12.0->frontend) (4.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from starlette>=0.12.0->frontend) (4.8.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn>=0.7.1->frontend) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click>=7.0->uvicorn>=0.7.1->frontend) (0.4.6)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pymupdf) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "!pip install frontend\n",
    "!pip install pymupdf\n",
    "import fitz  # PyMuPDF library for PDF extraction\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from langdetect import detect  # Import the language detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3174d2-918d-4b44-b883-137047b315d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ecb9e37-af72-4daa-90da-7e6e843ea0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s,.()\\[\\]{}\"\\'<>/\\\\|:;_\\-?!@#%&*+=\\^]', '', text)\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65e566e-c1b0-4c96-bb83-737d6eee8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\enigma\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install langdetect\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c2f2121-25d6-4a2d-a647-cd3c19fbe39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15287 > 512). Running this sequence through the model will result in indexing errors\n",
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'enfant a été élu à l'occasion de la première enquête de la cour de l'année précédente, et a été élu à l'occasion de la première enquête de l'année précédente, et a été élu à l'occasion de la première enquête de l'année précédente, et a été élu à l'occasion de la première enquête de\n"
     ]
    }
   ],
   "source": [
    "def translate_pdf(pdf_file_path):\n",
    "    # Extract text from the PDF file using PyMuPDF\n",
    "    doc = fitz.open(pdf_file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "\n",
    "    # Preprocess the extracted text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "\n",
    "    # Build the translation input\n",
    "    translation_input = f\"translate {preprocessed_text}\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(translation_input, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the translation\n",
    "    translation_ids = model.generate(input_ids, max_length=512, num_return_sequences=1, early_stopping=True)\n",
    "\n",
    "    # Decode and return the translation\n",
    "    translation = tokenizer.decode(translation_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return translation\n",
    "\n",
    "# Path to the PDF file you want to translate\n",
    "pdf_file_path = \"./uploads/AFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "\n",
    "# Translate the PDF file\n",
    "translated_text = translate_pdf(pdf_file_path)\n",
    "# print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f75b5bb-9d0f-4479-b814-e65e76b31fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "# Initialize the translation pipeline with source and target languages\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\", device=0, framework=\"pt\", use_fast=True, tokenizer=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "# Input PDF file path\n",
    "pdf_file_path = \"./uploads/AFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "\n",
    "# Output PDF file path\n",
    "output_pdf_path = \"translated_outputAFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "\n",
    "# Initialize a PDF canvas for the output file\n",
    "c = canvas.Canvas(output_pdf_path, pagesize=letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82789762-0f7e-423c-8a10-3e7e4648f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import transformers\n",
    "from transformers import TranslationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738377ae-5020-49b3-bae3-46d88fb31231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translator = TranslationPipeline(\n",
    "#     model=\"Helsinki-NLP/opus-mt-en-fr\",\n",
    "#     task=\"translation\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37fa276a-d476-49cd-9f19-c8680430f4e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot insert page beyond end of page tree",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5184\\459576930.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Function to translate text with a specified max_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# def translate_text(text, translator, max_length=2000):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5184\\459576930.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(pdf_document, start_page, end_page, translator, max_length)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Create a new page in the output PDF with the same dimensions as the original\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mpage_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mpage_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mnew_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_pdf_document\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Add the translated text to the new page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mnew_page\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranslated_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fitz\\utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(doc, pno, width, height)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[0mheight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mpage\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefault\u001b[0m \u001b[1;36m842\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mISO\u001b[0m \u001b[0mA4\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mPage\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \"\"\"\n\u001b[1;32m-> 1854\u001b[1;33m     \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_newPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1855\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpno\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fitz\\fitz.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, pno, width, height)\u001b[0m\n\u001b[0;32m   4817\u001b[0m         \u001b[1;34m\"\"\"Make a new PDF page.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_closed\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encrypted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4819\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"document closed or encrypted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4821\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDocument__newPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4822\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_page_refs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4824\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot insert page beyond end of page tree"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from transformers import pipeline\n",
    "# Function to translate text with a specified max_length\n",
    "# def translate_text(text, translator, max_length=2000):\n",
    "#     # Translate the text from English to French with the specified max_length\n",
    "#     translated_text = translator(text, max_length=max_length)\n",
    "#     return translated_text\n",
    "# translated_text = translate_text(text, translator, max_length=2000)  # Adjust max_length as needed\n",
    "\n",
    "# Function to create a new PDF document for translated text\n",
    "def create_translated_pdf(translated_texts, page_sizes):\n",
    "    translated_pdf = fitz.open()\n",
    "    for text, page_size in zip(translated_texts, page_sizes):\n",
    "        page = translated_pdf.new_page(width=page_size[0], height=page_size[1])\n",
    "        page.insert_text(text, fontsize=12)\n",
    "    return translated_pdf\n",
    "# Function to translate and append pages to the output PDF\n",
    "# Function to translate and append pages to the output PDF\n",
    "def translate_and_append(pdf_document, start_page, end_page, translator, max_length):\n",
    "    translated_pages = []  # Store translated pages\n",
    "\n",
    "    for page_num in range(start_page, end_page):\n",
    "        page = pdf_document[page_num]\n",
    "        text = page.get_text(\"text\")\n",
    "\n",
    "        # Translate the text from English to French with the specified max_length\n",
    "        translated_text = translator(text, max_length=max_length)\n",
    "\n",
    "        # Create a new page in the output PDF with the same dimensions as the original\n",
    "        page_width = int(page.rect.width)\n",
    "        page_height = int(page.rect.height)\n",
    "        new_page = output_pdf_document.new_page(page_width, page_height)\n",
    "\n",
    "        # Add the translated text to the new page\n",
    "        new_page.insert_text(text=translated_text, fontsize=12)\n",
    "\n",
    "        translated_pages.append(new_page)\n",
    "\n",
    "    return translated_pages\n",
    "\n",
    "\n",
    "# Set the max_length value for translation\n",
    "max_length = 800  # Adjust this value as needed\n",
    "\n",
    "# Translate and append pages to the output PDF\n",
    "translated_pages = translate_and_append(pdf_document, start_page, end_page, translator, max_length)\n",
    "\n",
    "# Add the translated pages to the output PDF\n",
    "for page in translated_pages:\n",
    "    output_pdf_document.insert_pdf(page)\n",
    "\n",
    "# Open the input PDF file\n",
    "pdf_file_path = \"./uploads/AFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "pdf_document = fitz.open(pdf_file_path)\n",
    "total_pages = len(pdf_document)\n",
    "\n",
    "# Initialize translation pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "\n",
    "# Set the number of pages to process at a time\n",
    "chunk_size = 10\n",
    "\n",
    "output_pdf_path = \"translated_outputAFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "output_pdf_document = fitz.open()\n",
    "\n",
    "# Translate and append pages to the output PDF in chunks\n",
    "start_page = 0\n",
    "while start_page < total_pages:\n",
    "    end_page = min(start_page + chunk_size, total_pages)\n",
    "    translated_texts = []\n",
    "\n",
    "    for page_num in range(start_page, end_page):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        translated_text = translate_text(text, translator)\n",
    "        translated_texts.append(translated_text)\n",
    "\n",
    "    # Get page sizes\n",
    "    page_sizes = [(int(page.rect.width), int(page.rect.height)) for page in pdf_document.pages(start_page, end_page)]\n",
    "\n",
    "    # Create a new PDF document for translated text\n",
    "    translated_pdf = create_translated_pdf(translated_texts, page_sizes)\n",
    "    output_pdf_document.insert_pdf(translated_pdf)\n",
    "\n",
    "    start_page = end_page\n",
    "\n",
    "# Save the output PDF file\n",
    "output_pdf_document.save(output_pdf_path)\n",
    "output_pdf_document.close()\n",
    "\n",
    "# Close the input PDF file\n",
    "pdf_document.close()\n",
    "\n",
    "print(f\"Translation complete. Translated PDF saved at: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9089892-99e2-40fa-8ac7-dfb5fe3e1314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'CINQUIME SECTION AFFAIRE C.P. et M.N. c. FRANCE (Requêtes nos 56513/17 et 56515/17) ARRT Art 8 • Vie privée et familiale • Refus des juridictions internes d’examiner l’action du requérant, affirmant être le père biologique d’un enfant, visant à contester la paternité légalement'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '   '}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 1 En l’affaire C.P. et M.N. c. France, La Cour européenne des droits de l’homme (cinquième section), siégeant en une chambre composée de : Georges Ravarani, président, Carlo Ranzoni, Mrti Mits, Stéphanie Mourou-Vikström, Mara El'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 2 5. Au début du mois de mars 2012, la requérante quitta son ancien compagnon et conclut un pacte civil de solidarité (PACS) avec le requérant, le 14 mars 2012. 6. Le 12 décembre 2012, la requérante saisit le juge aux affaires familiales (JAF) aux fins de faire fixer les mesures relatives aux deux'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 3 « (...) nul, à l’exception du ministère public, ne peut contester la filiation lorsque la possession d’état conforme à une reconnaissance a duré au moins cinq ans depuis la naissance ou la reconnaissance, si elle a été faite ultérieurement (...). » 13. Par ailleurs, il constata, d’une part, que l'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 4 (...) en outre, peu importe la révélation faite [au père légal] qu’il ne serait pas le père biologique de l’enfant dès l’année 2009, voire 2007, dès lors qu’il s’est toujours comporté comme tel ; (...) en outre, ainsi que l’ont justement retenu les premiers juges, l’enquête'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 5 Par ailleurs, conformément à l’article 311-1 du même code, la possession d’état s’établit par une réunion suffisante de faits qui révèlent le lien de filiation et de parenté entre une personne et la famille à laquelle elle est dite appartenir. Cet article précise de manière non exhaustive les principaux éléments pouvant'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 6 dispositions du code civil relatives à la filiation afin de sécuriser le lien de filiation et préserver les enfants des conflits de filiations. L’ordonnance no 2005-759 du 4 juillet 2005 portant réforme de la filiation a ainsi créé un article 333 prévoyant que, dès lors que la possession d’état d’enfant a'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 7 III. LES ACTIONS EN CONTESTATION DE PATERNITÉ APPELLENT LA MISE EN CAUSE DE L’ENFANT 26. L’action en contestation de paternité établie par un titre corroboré par la possession d’Etat implique d’attraire dans la cause, outre l’auteur de la reconnaissance dont la filiation est contest'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 8 EN DROIT I. JONCTION DES REQUTES 29. Eu égard à la similarité de l’objet des requêtes, la Cour juge opportun de les examiner ensemble dans un arrêt unique. II. SUR LA VIOLATION ALLÉGUÉE DE L’ARTICLE 8 DE LA CONVENTION 30. Les requérants se pla'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 9 L.D. et P.K. c. Bulgarie, nos 7949/11 et 45522/13,  54-56, 8 décembre 2016). 33. En l’espèce, la Cour ne voit aucune raison de se prononcer différemment s’agissant du requérant. Elle considère que la situation dénoncée par ce dernier'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 10 b) Le Gouvernement 37. Le Gouvernement soutient que les règles de droit interne applicables à l’action en contestation et reconnaissance de paternité, telles que prévues par le code civil, sont claires et poursuivent un but légitime, qui est d’assurer le respect du principe de sécurité juridique ainsi que le respect des'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 11 pour parvenir à la solution retenue et rechercher si un juste équilibre a été ménagé entre les différents intérêts en présence. Ce faisant, elle doit porter une attention particulière au principe essentiel selon lequel, chaque fois que la situation d’un enfant est en cause, son intérêt doit primer (voir notamment Wagner et J.M.W.'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 12 45. S’agissant des délais pour agir ou autres limitations à l’introduction d’une action en recherche ou contestation de paternité, la Cour admet que ces limites peuvent être justifiées par la volonté d’assurer la sécurité juridique et le caractère définitif des relations familiales et de protéger ainsi à la fois les'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 13 biologique, les juridictions internes n’ont pas su ménager un juste équilibre entre les droits et intérêts concurrents en présence. 49. La Cour doit donc, à la lumière de l’ensemble de l’affaire, d’une part, vérifier si les règles de computation du délai de forclusion ayant conduit les juridictions internes à déclarer l’action'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 14 52. La Cour observe par ailleurs, avec la cour d’appel, que le requérant n’a agi en contestation de paternité qu’au moment où la requérante demandait parallèlement la fixation de la résidence de N., en alternance chez sa mère et son père légal (paragraphes 6, 10 et'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 15 souhaitait pas être entendu par les juges et voulait qu’on « le laisse tranquille » (paragraphe 14 ci-dessus). La Cour estime donc que la cour d’appel, sous le contrôle de la Cour de cassation (paragraphe 17 ci-dessus), a pu estimer qu’il n’était pas dans l’intérêt supérieur de l'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 16 Fait en français, puis communiqué par écrit le 12 octobre 2023, en application de l’article 77  2 et 3 du règlement. Martina Keller Georges Ravarani Greffière adjointe Président Au présent arrêt se trouve joint, conformément aux articles 45  2 de la Convention et 74  2 du règlement, l’exposé de l'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE – OPINION SÉPARÉE 17 OPINION DISSIDENTE DE LA JUGE MOUROU-VIKSTRM Je ne me suis pas ralliée à la majorité de la chambre qui a conclu à une non-violation de l’article 8 de la Convention dans cette affaire qui concerne les exigences procédurales'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE – OPINION SÉPARÉE 18 Enfin, la Cour de cassation a opéré dans la motivation de son arrêt une substitution des motifs concernant l’irrecevabilité de l’action. En effet, elle a visé l’article 2241 du code civil qui est relatif aux causes d’interruption du délai de forclusion mais'}]\n",
      "[{'translation_text': 'ARRT C.P. et M.N. c. FRANCE 19 ANNEXE Liste des requêtes No Requête No Nom de l’affaire Introduite le Représenté par 1. 56513/17 C.P. c. France 01/08/2017 Patrice SPINOSI 2. 56515/17 M.N. c. France 01/08/2017 Patrice SPINOSI'}]\n",
      "Translation complete. Translated PDF saved at: translated_outputAFFAIRE C.P. ET M.N. c. FRANCE.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from transformers import pipeline\n",
    "from fitz.utils import Point\n",
    "\n",
    "# Function to create a new PDF document for a single page of translated text\n",
    "def create_translated_page(translated_text, page_size):\n",
    "    translated_pdf = fitz.open()\n",
    "    page = translated_pdf.new_page(width=page_size[0], height=page_size[1])\n",
    "    page.insert_text(Point(50, 50), translated_text, fontsize=12)  # Adjust the position as needed\n",
    "    return translated_pdf\n",
    "\n",
    "# Set the max_length value for translation\n",
    "max_length = 800  # Adjust this value as needed\n",
    "\n",
    "# Function to translate a single page and append it to the output PDF\n",
    "def translate_and_append_single_page(page, translator):\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    # Translate the text from English to French\n",
    "    translated_text = translator(text, max_length=2000)\n",
    "    print(translated_text)\n",
    "\n",
    "    # Get the width and height of the page\n",
    "    page_width = int(page.rect.width)\n",
    "    page_height = int(page.rect.height)\n",
    "\n",
    "    # Create a new PDF document for the translated page\n",
    "    translated_pdf = create_translated_page(translated_text, (page_width, page_height))\n",
    "\n",
    "    return translated_pdf\n",
    "\n",
    "# Open the input PDF file\n",
    "pdf_file_path = \"./uploads/AFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "pdf_document = fitz.open(pdf_file_path)\n",
    "total_pages = len(pdf_document)\n",
    "\n",
    "# Initialize translation pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "\n",
    "# Set the number of pages to process at a time\n",
    "chunk_size = 1\n",
    "\n",
    "output_pdf_path = \"translated_outputAFFAIRE C.P. ET M.N. c. FRANCE.pdf\"\n",
    "\n",
    "# Create a new output PDF document\n",
    "output_pdf_document = fitz.open()\n",
    "\n",
    "# Translate and append pages to the output PDF one at a time\n",
    "for page_num in range(total_pages):\n",
    "    page = pdf_document[page_num]\n",
    "\n",
    "    # Translate and append the current page\n",
    "    translated_pdf = translate_and_append_single_page(page, translator)\n",
    "\n",
    "    # Add the translated page to the output PDF\n",
    "    output_pdf_document.insert_pdf(translated_pdf)\n",
    "    # outputFile.append()\n",
    "\n",
    "# Save the output PDF file\n",
    "output_pdf_document.save(output_pdf_path)\n",
    "output_pdf_document.close()\n",
    "\n",
    "# Close the input PDF file\n",
    "pdf_document.close()\n",
    "\n",
    "print(f\"Translation complete. Translated PDF saved at: {output_pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb98db37-85f9-49b7-bc2b-6924ae12b45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(<new PDF, doc# 63>)\n"
     ]
    }
   ],
   "source": [
    "print(translated_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a75f5-239a-4435-b4ec-8c9bcf88ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Remove page numbers\n",
    "\n",
    "\n",
    "#     # Remove special characters \n",
    "#     text = re.sub(r'[^\\w\\s,.()\\[\\]{}\"\\'<>/\\\\|:;_\\-?!@#%&*+=\\^]', '', text)\n",
    "\n",
    "#     # Convert text to lowercase\n",
    "#     text = text.lower()\n",
    "\n",
    "#     return text\n",
    "\n",
    "# # Assuming you have a function called extract_text_from_pdf that extracts text from a PDF\n",
    "# # Example usage:\n",
    "# preprocessed_text = preprocess_text(df)\n",
    "# print(preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "978b3282-9d86-4285-8b03-2fc1204fdc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\enigma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py:1013: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "t5 = pipeline(model=\"t5-base\", tokenizer=\"t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "394fd5e4-b5cf-47c8-81d3-10b2d9224707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    return t5(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc8518e0-2407-4d74-98f4-cb875e534c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Hallo da, allgemeine kenobi Sie sind ein mutiger'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"hello there, general kenobi you are a bold one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba59db7c-2c4f-47d7-8724-d7cc71d5afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# model_name = \"t5-base\"\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95846a0b-d5ef-494c-a74e-30ed7b28a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Your long Turkish text\n",
    "# turkish_text = preprocessed_text\n",
    "\n",
    "# # Split the text into segments\n",
    "# max_seq_length = 512\n",
    "# segments = [turkish_text[i:i+max_seq_length] for i in range(0, len(turkish_text), max_seq_length)]\n",
    "\n",
    "# # Translate each segment\n",
    "# translated_text_segments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5736e559-3500-4d38-9f10-2a3837704503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment = segments[0]\n",
    "# input_ids = tokenizer.encode(\"translate Turkish to English: \" + segment, return_tensors=\"pt\")\n",
    "# translation = model.generate(input_ids, max_length=150, num_beams=4, no_repeat_ngram_size=2, early_stopping=True)\n",
    "# translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "# translated_text_segments.append(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90d52428-2c34-4619-9c1c-1e1e29c46708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Translation:  türkiye (requête no 56578/11) arrêt art 8 vie privée mise sous tutelle judiciaire de la requérante, à lissue dune procédure ayant conclu quelle souffrait dun trouble mental entravant sa capacité dagir existence de garanties effectives dans la procédure interne pour prévenir les abus en veillant  ce que les droits et les interess of the respondent soient pris è compte participation de cette\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Combine the translated segments\n",
    "# translated_text = \" \".join(translated_text_segments)\n",
    "\n",
    "# # print(\"Turkish Text: \", turkish_text)\n",
    "# print(\"English Translation: \", translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba21475-f48d-4d68-bb4b-7103f4153765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
